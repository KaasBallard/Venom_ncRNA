{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step11\n",
    "Date: May 13, 2024\n",
    "Purpose: The purpose of this script is to do some formating and data scrubbing for the blast output generated by the previous step.\n",
    "The previous step in the pipeline is: blast_miRBase_alignment_2024-5-13.sh (/home/administrator/Documents/Kaas/Venom_ncRNA_project/Scripts/blast/blast_miRBase_alignment_2024-5-13.sh)\n",
    "The next step in this pipeline is: 3UTR_5UTR_exon_df_fusion_2024-5-13.ipynb (/home/administrator/Documents/Kaas/Venom_ncRNA_project/Scripts/Python/3UTR_5UTR_exon_df_fusion_2024-5-13.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import needed packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function that can check and print if there are any query sequences between filtering steps:\n",
    "def non_matching_queries(pre_filtering_df, post_filtering_df):\n",
    "    # Create a data frame for only unique query sequences prior to filtering\n",
    "    query_pre_filtering_df = pre_filtering_df['Query'].unique()\n",
    "    # Create a data frame for only unique query sequneces after filtering\n",
    "    query_post_filtering_df = post_filtering_df['Query'].unique()\n",
    "\n",
    "    # Find queries that don't match between data sets\n",
    "    non_matching_queries = set(query_pre_filtering_df) ^ set(query_post_filtering_df)\n",
    "\n",
    "    # Print any queries that are not present after filtering or print that all queries are present\n",
    "    if non_matching_queries:\n",
    "        print('Queries sequences are missing after filtering. The non-matching queries are:')\n",
    "        for query in non_matching_queries:\n",
    "            print(query)\n",
    "    else:\n",
    "        print('No query sequences have been lost due to filtering.')\n",
    "\n",
    "\n",
    "def find_best_blast_hit(row):\n",
    "    closest_species = None\n",
    "\n",
    "    for species in ['oha', 'pbv', 'aca', 'ami', 'cpi', 'xla', 'hsa', 'mmu', 'cfa', 'dre', 'cel', 'dme', 'dpu', 'ath', 'sly', 'zma']:\n",
    "        if not pd.isnull(row[species]):\n",
    "            closest_species = species\n",
    "            break\n",
    "\n",
    "    if closest_species is not None:\n",
    "        # Split the blast hits by comma and choose one randomly\n",
    "        blast_hits = row[closest_species].split(', ')\n",
    "        selected_hit = random.choice(blast_hits)\n",
    "        return f\"{closest_species}-{selected_hit}\"\n",
    "    \n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add another variable for the blast alignment so that it can be added to the final files\n",
    "blast_alignment_df = pd.read_csv('/home/administrator/Documents/Kaas/Venom_ncRNA_project/Results/blast/miRBase/mature_mir-miRBase_alignment.tab', sep='\\t')\n",
    "\n",
    "# Add column names\n",
    "blast_alignment_df.columns = ['Query', 'Subject', 'Blast.Percent.Identity', 'Blast.Alignment.Length', 'Blast.Mismatches', \n",
    "                              'Blast.Gap.Openings', 'Blast.Query.Start', 'Blast.Query.End', 'Blast.Subject.Start', 'Blast.Subject.End', \n",
    "                              'E.value', 'Bit.Score']\n",
    "\n",
    "# Create a new column miRNA.Start and miRNA.End\n",
    "blast_alignment_df['miRNA.Start'] = blast_alignment_df['Query'].str.extract(r':(\\d+)-').astype(int) \n",
    "blast_alignment_df['miRNA.End'] = blast_alignment_df['Query'].str.extract(r'-(\\d+)').astype(int)\n",
    "# Extract only the cluster name information:\n",
    "blast_alignment_df['Query'] = blast_alignment_df['Query'].str.split('.').str[0]\n",
    "# Create new column that is the length of the miRNA\n",
    "blast_alignment_df['miRNA.Length'] = blast_alignment_df['miRNA.End'] - blast_alignment_df['miRNA.Start']\n",
    "# Create a new column that is the absolute value of the Query Length plus 1\n",
    "blast_alignment_df['Blast.Query.Length'] = abs(blast_alignment_df['Blast.Query.End'] - blast_alignment_df['Blast.Query.Start']) + 1\n",
    "# Create a new column that is the absolute value of the Subject Length plus 1\n",
    "blast_alignment_df['Blast.Subject.Length'] = abs(blast_alignment_df['Blast.Subject.End'] - blast_alignment_df['Blast.Subject.Start']) + 1\n",
    "# Drop miRNA.End and miRNA.Start\n",
    "blast_alignment_df.drop(['miRNA.Start', 'miRNA.End'], axis=1, inplace=True)\n",
    "\n",
    "# Take the species abreviation out and give it it's own column\n",
    "blast_alignment_df['Species.Abbreviation'] = blast_alignment_df['Subject'].str.split('-', n=1).str[0]\n",
    "blast_alignment_df['Blast.Hits'] = blast_alignment_df['Subject'].str.split('-', n=1).str[1]\n",
    "\n",
    "# New column order\n",
    "column_order = ['Query', 'miRNA.Length', 'Subject', 'Species.Abbreviation', 'Blast.Hits', 'Blast.Percent.Identity', 'Blast.Alignment.Length', 'Blast.Mismatches', \n",
    "                'Blast.Gap.Openings', 'Blast.Query.Start', 'Blast.Query.End', 'Blast.Query.Length', 'Blast.Subject.Start', 'Blast.Subject.End', 'Blast.Subject.Length',\n",
    "                'E.value', 'Bit.Score' ] # Create new column order\n",
    "blast_alignment_df = blast_alignment_df[column_order] # Reorder columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No query sequences have been lost due to filtering.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nResult:\\nNo query sequences have been lost due to filtering.\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a list of species abbreviations to keep\n",
    "'''\n",
    "Species are in he same order: \n",
    "\n",
    "        - Arabidopsis thaliana (ath)\n",
    "\t\t- Zea mays (zma)\n",
    "\t\t- Caenorhabditis elegans (cel)\n",
    "\t\t- Daphnia pulex (dpu)\n",
    "\t\t- Homo sapiens (hsa)\n",
    "\t\t- Anolis carolinensis (aca)\n",
    "\t\t- Danio rerio (dre)\n",
    "\t\t- Drosophila melanogaster (dme)\n",
    "\t\t- Mus musculus (mmu)\n",
    "\t\t- Canis familiaris (cfa)\n",
    "\t\t- Solanum lycopersicum (sly)\n",
    "        - Ophiophagus hannah (oha)\n",
    "\t\t- Python bivittatus (pbv)\n",
    "\t\t- Alligator mississippiensis (ami)\n",
    "\t\t- Chrysemys picta (cpi)\n",
    "\t\t- Xenopus laevis (xla)\n",
    "'''\n",
    "\n",
    "species_to_keep = [\n",
    "    'ath', 'zma', 'cel', 'dpu', 'hsa', 'aca', 'dre', 'dme', 'mmu', 'cfa', 'sly', \n",
    "    'oha', 'pbv', 'ami', 'cpi', 'xla'\n",
    "]\n",
    "\n",
    "# Create a boolean mask indicating which rows to keep\n",
    "mask = blast_alignment_df['Species.Abbreviation'].isin(species_to_keep)\n",
    "\n",
    "# Apply filter\n",
    "taxa_filtered_df = blast_alignment_df[mask]\n",
    "\n",
    "# Check what queries, if any, have gone missing.\n",
    "non_matching_queries(blast_alignment_df, taxa_filtered_df)\n",
    "'''\n",
    "Result:\n",
    "No query sequences have been lost due to filtering.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queries sequences are missing after filtering. The non-matching queries are:\n",
      "Cluster_1858\n",
      "Cluster_1718\n",
      "Cluster_182\n",
      "Cluster_988\n",
      "Cluster_186\n",
      "Cluster_1226\n",
      "Cluster_807\n",
      "Cluster_1337\n",
      "Cluster_341\n",
      "Cluster_1326\n",
      "Cluster_1578\n",
      "Cluster_1395\n",
      "Cluster_196\n",
      "Cluster_1292\n",
      "Cluster_1640\n",
      "Cluster_853\n",
      "Cluster_1037\n",
      "Cluster_1428\n",
      "Cluster_919\n",
      "Cluster_1666\n",
      "Cluster_659\n"
     ]
    }
   ],
   "source": [
    "# E-value threshold\n",
    "e_value_threshold = 0.001\n",
    "# Filter out E.values that are too low.\n",
    "e_value_filtered_df = taxa_filtered_df[taxa_filtered_df['E.value'] < e_value_threshold]\n",
    "\n",
    "# Check what queries, if any, have gone missing.\n",
    "non_matching_queries(taxa_filtered_df, e_value_filtered_df)\n",
    "'''\n",
    "Queries sequences are missing after filtering. The non-matching queries are:\n",
    "Cluster_1858\n",
    "Cluster_1718\n",
    "Cluster_182\n",
    "Cluster_988\n",
    "Cluster_186\n",
    "Cluster_1226\n",
    "Cluster_807\n",
    "Cluster_1337\n",
    "Cluster_341\n",
    "Cluster_1326\n",
    "Cluster_1578\n",
    "Cluster_1395\n",
    "Cluster_196\n",
    "Cluster_1292\n",
    "Cluster_1640\n",
    "Cluster_853\n",
    "Cluster_1037\n",
    "Cluster_1428\n",
    "Cluster_919\n",
    "Cluster_1666\n",
    "Cluster_659\n",
    "'''\n",
    "\n",
    "# Create a data frame for clusters that were lost from filtering by e-value\n",
    "# Create a list of lost clusters\n",
    "lost_clusters = [\n",
    "    'Cluster_1858',\n",
    "    'Cluster_1718',\n",
    "    'Cluster_182',\n",
    "    'Cluster_988',\n",
    "    'Cluster_186',\n",
    "    'Cluster_1226',\n",
    "    'Cluster_807',\n",
    "    'Cluster_1337',\n",
    "    'Cluster_341',\n",
    "    'Cluster_1326',\n",
    "    'Cluster_1578',\n",
    "    'Cluster_1395',\n",
    "    'Cluster_196',\n",
    "    'Cluster_1292',\n",
    "    'Cluster_1640',\n",
    "    'Cluster_853',\n",
    "    'Cluster_1037',\n",
    "    'Cluster_1428',\n",
    "    'Cluster_919',\n",
    "    'Cluster_1666',\n",
    "    'Cluster_659'\n",
    "]\n",
    "\n",
    "# Get lost clusters and put them a data frame\n",
    "lost_clusters_e_value_df = taxa_filtered_df[taxa_filtered_df['Query'].isin(lost_clusters)]\n",
    "\n",
    "# Group by 'Query' (cluster) and find the row with the lowest E-value for each group\n",
    "best_hits_for_lost_clusters_df = lost_clusters_e_value_df.loc[lost_clusters_e_value_df.groupby('Query')['E.value'].idxmin()]\n",
    "\n",
    "best_hits_for_lost_clusters_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pivoted data frame for the first missing clusters data frame\n",
    "pivot_best_lost_clusters_df = pd.pivot_table(\n",
    "    best_hits_for_lost_clusters_df,\n",
    "    index=['Query', 'miRNA.Length', 'Blast.Percent.Identity', 'Blast.Alignment.Length', 'Blast.Mismatches', 'Blast.Gap.Openings', \n",
    "           'Blast.Query.Start', 'Blast.Query.End', 'Blast.Query.Length', 'Blast.Subject.Start', 'Blast.Subject.End', 'Blast.Subject.Length', \n",
    "           'E.value', 'Bit.Score'],\n",
    "    columns='Species.Abbreviation',\n",
    "    values='Blast.Hits',\n",
    "    aggfunc=lambda x: ', '.join(x)\n",
    ")\n",
    "#print(pivot_best_lost_clusters_df)\n",
    "\n",
    "# Reset index\n",
    "pivot_best_lost_clusters_df.reset_index(inplace=True)\n",
    "\n",
    "# Add missing columns so the function works\n",
    "pivot_best_lost_clusters_df['pbv'] = np.nan\n",
    "pivot_best_lost_clusters_df['cpi'] = np.nan\n",
    "pivot_best_lost_clusters_df['dre'] = np.nan\n",
    "pivot_best_lost_clusters_df['cel'] = np.nan\n",
    "pivot_best_lost_clusters_df['dpu'] = np.nan\n",
    "pivot_best_lost_clusters_df['sly'] = np.nan\n",
    "\n",
    "\n",
    "# Set to new df\n",
    "best_lost_matches_df1 = pivot_best_lost_clusters_df\n",
    "best_lost_matches_df2 = best_lost_matches_df1\n",
    "\n",
    "# Here I run the above function to create a new column\n",
    "best_lost_matches_df1['Best.miRNA.Blast.Hits'] = best_lost_matches_df1.apply(find_best_blast_hit, axis=1)\n",
    "\n",
    "# Create another column for just regular names\n",
    "best_lost_matches_df1['Base.Putative.miRNA.Name'] = best_lost_matches_df1['Best.miRNA.Blast.Hits'].str.split('-', n=1).str[1]\n",
    "\n",
    "# Create another column to classify what whether the miRNA is probably the same or not.\n",
    "best_lost_matches_df1['miRNA.Identity.Type'] = 'De-Novo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No query sequences have been lost due to filtering.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nResult:\\nNo query sequences have been lost due to filtering.\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Further filter down to so that the percent identity is exactly the same\n",
    "percent_id_df = e_value_filtered_df[e_value_filtered_df['Blast.Percent.Identity'] == 100]\n",
    "\n",
    "# Check what queries are missing after filtering for percent identity\n",
    "non_matching_queries(e_value_filtered_df, percent_id_df)\n",
    "'''\n",
    "Result:\n",
    "No query sequences have been lost due to filtering.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are length_match_df and miRNA_length_match_df the same? True\n",
      "Queries sequences are missing after filtering. The non-matching queries are:\n",
      "Cluster_1863\n",
      "Cluster_866\n",
      "Cluster_1339\n",
      "Cluster_856\n",
      "Cluster_1692\n",
      "Queries sequences are missing after filtering. The non-matching queries are:\n",
      "Cluster_1772\n",
      "Cluster_822\n"
     ]
    }
   ],
   "source": [
    "# Create a new dataframe where the alignment length and the query end match exactly so that there isn't any chance of an alignment being non-identical due to the alignment starting at a different place than the miRNA\n",
    "length_match_df = percent_id_df[percent_id_df['Blast.Alignment.Length'] == percent_id_df['miRNA.Length']]\n",
    "\n",
    "# Further filter down based on whether the miRNA.Length equals the length of the subject sequence\n",
    "miRNA_length_match_df = length_match_df[length_match_df['miRNA.Length'] == length_match_df['Blast.Subject.Length']]\n",
    "print('Are length_match_df and miRNA_length_match_df the same?', miRNA_length_match_df.equals(length_match_df))\n",
    "\n",
    "# Check if any queries were lost from filtering\n",
    "non_matching_queries(percent_id_df, miRNA_length_match_df)\n",
    "'''\n",
    "Queries sequences are missing after filtering. The non-matching queries are:\n",
    "Cluster_1863\n",
    "Cluster_866\n",
    "Cluster_1339\n",
    "Cluster_856\n",
    "Cluster_1692\n",
    "'''\n",
    "# Create a list of filtered out clusters\n",
    "non_matching_length = [\n",
    "    'Cluster_1863',\n",
    "    'Cluster_866',\n",
    "    'Cluster_1339',\n",
    "    'Cluster_856',\n",
    "    'Cluster_1692'\n",
    "]\n",
    "\n",
    "# Check if create dataframe of lost clusters\n",
    "non_matching_length_df = percent_id_df[percent_id_df['Query'].isin(non_matching_length)]\n",
    "\n",
    "# Further filter down based on whether the length of the subject sequence equals either it's start or end.\n",
    "# This will take out sequences that have an extra nucleotide on either end\n",
    "best_length_match_df = miRNA_length_match_df[\n",
    "    (miRNA_length_match_df['miRNA.Length'] == miRNA_length_match_df['Blast.Subject.End']) |\n",
    "    (miRNA_length_match_df['miRNA.Length'] == miRNA_length_match_df['Blast.Subject.Start'])\n",
    "]\n",
    "\n",
    "# Check if any queries were lost after filtering for homolog length identity\n",
    "non_matching_queries(miRNA_length_match_df, best_length_match_df)\n",
    "'''\n",
    "Result:\n",
    "Queries sequences are missing after filtering. The non-matching queries are:\n",
    "Cluster_1772\n",
    "Cluster_822\n",
    "'''\n",
    "\n",
    "# Create a new data frame of lost clusters that were taken\n",
    "# Create a list of Clusters that were filtered out\n",
    "filtered_out_clusters = [\n",
    "    'Cluster_1772',\n",
    "    'Cluster_822'\n",
    "]\n",
    "\n",
    "# Get lost clusters and put them a dataframe\n",
    "length_filtered_lost_clusters_df = miRNA_length_match_df[miRNA_length_match_df['Query'].isin(filtered_out_clusters)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Species.Abbreviation         Query  miRNA.Length  Blast.Percent.Identity  \\\n",
      "0                     Cluster_1339            22                   100.0   \n",
      "1                     Cluster_1692            22                   100.0   \n",
      "2                     Cluster_1863            22                   100.0   \n",
      "3                      Cluster_856            22                   100.0   \n",
      "4                      Cluster_866            23                   100.0   \n",
      "\n",
      "Species.Abbreviation  Blast.Alignment.Length  Blast.Mismatches  \\\n",
      "0                                         21                 0   \n",
      "1                                         21                 0   \n",
      "2                                         21                 0   \n",
      "3                                         21                 0   \n",
      "4                                         22                 0   \n",
      "\n",
      "Species.Abbreviation  Blast.Gap.Openings  Blast.Query.Start  Blast.Query.End  \\\n",
      "0                                      0                  1               21   \n",
      "1                                      0                  1               21   \n",
      "2                                      0                  2               22   \n",
      "3                                      0                  1               21   \n",
      "4                                      0                  1               22   \n",
      "\n",
      "Species.Abbreviation  Blast.Query.Length  Blast.Subject.Start  ...  dre  aca  \\\n",
      "0                                     21                    1  ...  NaN  NaN   \n",
      "1                                     21                    1  ...  NaN  NaN   \n",
      "2                                     21                    1  ...  NaN  NaN   \n",
      "3                                     21                    1  ...  NaN  NaN   \n",
      "4                                     22                    1  ...  NaN  NaN   \n",
      "\n",
      "Species.Abbreviation  hsa  dpu cel zma ath  Best.miRNA.Blast.Hits  \\\n",
      "0                     NaN  NaN NaN NaN NaN        oha-miR-129b-5p   \n",
      "1                     NaN  NaN NaN NaN NaN        pbv-miR-200b-3p   \n",
      "2                     NaN  NaN NaN NaN NaN         xla-miR-29c-3p   \n",
      "3                     NaN  NaN NaN NaN NaN        oha-let-7f-2-3p   \n",
      "4                     NaN  NaN NaN NaN NaN         xla-miR-29c-3p   \n",
      "\n",
      "Species.Abbreviation  Base.Putative.miRNA.Name  miRNA.Identity.Type  \n",
      "0                                  miR-129b-5p   Potential-Identity  \n",
      "1                                  miR-200b-3p   Potential-Identity  \n",
      "2                                   miR-29c-3p   Potential-Identity  \n",
      "3                                  let-7f-2-3p   Potential-Identity  \n",
      "4                                   miR-29c-3p   Potential-Identity  \n",
      "\n",
      "[5 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "# Group by 'Query' (cluster) and find the row with the highest alignment length\n",
    "non_matching_length_df = non_matching_length_df.loc[non_matching_length_df.groupby('Query')['Blast.Alignment.Length'].idxmax()]\n",
    "\n",
    "\n",
    "# Create a new data frame that is a pivoted dataframe of what was lost after filter for length\n",
    "pivot_non_matching_length_df = pd.pivot_table(\n",
    "    non_matching_length_df,\n",
    "    index=['Query', 'miRNA.Length', 'Blast.Percent.Identity', 'Blast.Alignment.Length', 'Blast.Mismatches', 'Blast.Gap.Openings', \n",
    "           'Blast.Query.Start', 'Blast.Query.End', 'Blast.Query.Length', 'Blast.Subject.Start', 'Blast.Subject.End', 'Blast.Subject.Length', \n",
    "           'E.value', 'Bit.Score'],\n",
    "    columns='Species.Abbreviation',\n",
    "    values='Blast.Hits',\n",
    "    aggfunc=lambda x: ', '.join(x)\n",
    ")\n",
    "\n",
    "# Print to check if it worked\n",
    "#print(pivot_non_matching_length_df)\n",
    "\n",
    "# Assign to new data frame\n",
    "best_missing_matches_by_length_df = pivot_non_matching_length_df\n",
    "\n",
    "# Reset index\n",
    "best_missing_matches_by_length_df.reset_index(inplace=True)\n",
    "\n",
    "# Add missing columns\n",
    "best_missing_matches_by_length_df['ami'] = np.nan\n",
    "best_missing_matches_by_length_df['cpi'] = np.nan\n",
    "best_missing_matches_by_length_df['sly'] = np.nan\n",
    "best_missing_matches_by_length_df['cfa'] = np.nan\n",
    "best_missing_matches_by_length_df['mmu'] = np.nan\n",
    "best_missing_matches_by_length_df['dme'] = np.nan\n",
    "best_missing_matches_by_length_df['dre'] = np.nan\n",
    "best_missing_matches_by_length_df['aca'] = np.nan\n",
    "best_missing_matches_by_length_df['hsa'] = np.nan\n",
    "best_missing_matches_by_length_df['dpu'] = np.nan\n",
    "best_missing_matches_by_length_df['cel'] = np.nan\n",
    "best_missing_matches_by_length_df['zma'] = np.nan\n",
    "best_missing_matches_by_length_df['ath'] = np.nan\n",
    "\n",
    "# Use function to create best hits column\n",
    "best_missing_matches_by_length_df['Best.miRNA.Blast.Hits'] = best_missing_matches_by_length_df.apply(find_best_blast_hit, axis=1)\n",
    "\n",
    "# Add putative miRNA names\n",
    "best_missing_matches_by_length_df['Base.Putative.miRNA.Name'] = best_missing_matches_by_length_df['Best.miRNA.Blast.Hits'].str.split('-', n=1).str[1]\n",
    "\n",
    "# Create another column to classify the likelihood of the name being correct\n",
    "best_missing_matches_by_length_df['miRNA.Identity.Type'] = 'Potential-Identity'\n",
    "print(best_missing_matches_by_length_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new data frame that is a pivoted dataframe of what was lost after filter for length\n",
    "pivot_length_filtered_lost_clusters_df = pd.pivot_table(\n",
    "    length_filtered_lost_clusters_df,\n",
    "    index=['Query', 'miRNA.Length', 'Blast.Percent.Identity', 'Blast.Alignment.Length', 'Blast.Mismatches', 'Blast.Gap.Openings', \n",
    "           'Blast.Query.Start', 'Blast.Query.End', 'Blast.Query.Length', 'Blast.Subject.Start', 'Blast.Subject.End', 'Blast.Subject.Length', \n",
    "           'E.value', 'Bit.Score'],\n",
    "    columns='Species.Abbreviation',\n",
    "    values='Blast.Hits',\n",
    "    aggfunc=lambda x: ', '.join(x)\n",
    ")\n",
    "\n",
    "# Reset index to flatten the multi-index\n",
    "pivot_length_filtered_lost_clusters_df.reset_index(inplace=True)\n",
    "\n",
    "# Add missing columns so the function works\n",
    "pivot_length_filtered_lost_clusters_df['ath'] = np.nan\n",
    "pivot_length_filtered_lost_clusters_df['cfa'] = np.nan\n",
    "pivot_length_filtered_lost_clusters_df['ami'] = np.nan\n",
    "pivot_length_filtered_lost_clusters_df['ath'] = np.nan\n",
    "pivot_length_filtered_lost_clusters_df['cel'] = np.nan\n",
    "pivot_length_filtered_lost_clusters_df['dme'] = np.nan\n",
    "pivot_length_filtered_lost_clusters_df['dpu'] = np.nan\n",
    "pivot_length_filtered_lost_clusters_df['hsa'] = np.nan\n",
    "pivot_length_filtered_lost_clusters_df['sly'] = np.nan\n",
    "pivot_length_filtered_lost_clusters_df['zma'] = np.nan\n",
    "\n",
    "\n",
    "\n",
    "# Here I create a dataframe to equal the pivoted current one so I can do things to it with altering the old one\n",
    "best_lost_matches_df2 = pivot_length_filtered_lost_clusters_df\n",
    "\n",
    "# Here I run the above functions to creat new columns that have good matches for each miRNA\n",
    "best_lost_matches_df2['Best.miRNA.Blast.Hits'] = best_lost_matches_df2.apply(find_best_blast_hit, axis=1)\n",
    "\n",
    "# Create another column for just regular names without the species attachment\n",
    "best_lost_matches_df2['Base.Putative.miRNA.Name'] = best_lost_matches_df2['Best.miRNA.Blast.Hits'].str.split('-', n=1).str[1]\n",
    "\n",
    "# Create another column to classify what whether the miRNA is probably the same or not.\n",
    "best_lost_matches_df2['miRNA.Identity.Type'] = 'Probable-Identity'\n",
    "\n",
    "# Check if it worked\n",
    "#print(best_lost_matches_df2['miRNA.Name'].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new data frame that is a pivoted data frame of the the most filtered data frame so I can figure out what the best hits are\n",
    "pivot_best_length_match_df = pd.pivot_table(\n",
    "    best_length_match_df,\n",
    "    index=['Query', 'miRNA.Length', 'Blast.Percent.Identity', 'Blast.Alignment.Length', 'Blast.Mismatches', 'Blast.Gap.Openings', \n",
    "           'Blast.Query.Start', 'Blast.Query.End', 'Blast.Query.Length', 'Blast.Subject.Start', 'Blast.Subject.End', 'Blast.Subject.Length', \n",
    "           'E.value', 'Bit.Score'],\n",
    "    columns='Species.Abbreviation',\n",
    "    values='Blast.Hits',\n",
    "    aggfunc=lambda x: ', '.join(x)\n",
    ")\n",
    "\n",
    "# Reset index to flatten the multi-index\n",
    "pivot_best_length_match_df.reset_index(inplace=True)\n",
    "\n",
    "# Here I create a dataframe to equal the pivoted current one so I can do things to it with altering the old one\n",
    "best_matches_by_species_df = pivot_best_length_match_df\n",
    "\n",
    "# Here I run the above functions to creat new columns that have good matches for each miRNA\n",
    "best_matches_by_species_df['Best.miRNA.Blast.Hits'] = best_matches_by_species_df.apply(find_best_blast_hit, axis=1)\n",
    "\n",
    "# Create another column for just regular names without the species attachment\n",
    "best_matches_by_species_df['Base.Putative.miRNA.Name'] = best_matches_by_species_df['Best.miRNA.Blast.Hits'].str.split('-', n=1).str[1]\n",
    "\n",
    "'''\n",
    "After I pivoted the dataframe and added the new columns I noticed that some of the new columns have multiple entries in them. Since all of these entries at this\n",
    "point are equally good statistically, I decided to just have it decided randomly.\n",
    "'''\n",
    "\n",
    "# Create another column to classify what whether the miRNA is probably the same or not.\n",
    "best_matches_by_species_df['miRNA.Identity.Type'] = 'Very-Probable-Identity'\n",
    "\n",
    "# Check if it worked\n",
    "#print(best_matches_by_species_df['miRNA.Name'].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No query sequences have been lost due to filtering.\n",
      "No query sequences have been lost due to filtering.\n",
      "No query sequences have been lost due to filtering.\n"
     ]
    }
   ],
   "source": [
    "# Concatenate from top to bottom\n",
    "final_df = pd.concat([best_matches_by_species_df, best_lost_matches_df2, best_lost_matches_df1, best_missing_matches_by_length_df], axis=0, ignore_index=True)\n",
    "final_df2 = pd.concat([best_matches_by_species_df, best_lost_matches_df2, best_lost_matches_df1, best_missing_matches_by_length_df], axis=0, ignore_index=True)\n",
    "\n",
    "# Reorder dataframe\n",
    "column_order = ['Query','Best.miRNA.Blast.Hits', 'Base.Putative.miRNA.Name', 'miRNA.Identity.Type',\n",
    "                'oha', 'pbv', 'aca', 'ami', 'cpi', 'xla', 'hsa', 'mmu', 'cfa', 'dre', 'cel', 'dme', 'dpu', 'ath', 'sly', 'zma', \n",
    "                'miRNA.Length', 'Blast.Percent.Identity', 'Blast.Alignment.Length', 'Blast.Mismatches', \n",
    "                'Blast.Gap.Openings', 'Blast.Query.Start', 'Blast.Query.End', 'Blast.Query.Length', 'Blast.Subject.Start', 'Blast.Subject.End', 'Blast.Subject.Length',\n",
    "                'E.value', 'Bit.Score' ]\n",
    "\n",
    "# Apply column order\n",
    "final_df = final_df[column_order]\n",
    "\n",
    "# Take out the species abbreviation again\n",
    "final_df['Species.Abbreviation'] = final_df['Best.miRNA.Blast.Hits'].str.split('-', n=1).str[0]\n",
    "\n",
    "def remove_other_species_hits(final_df):\n",
    "    # Define the hierarchy of species abbreviations to prioritize\n",
    "    species_hierarchy = ['oha', 'pbv', 'aca', 'ami', 'cpi', 'xla', 'hsa', 'mmu', 'cfa', 'dre', 'cel', 'dme', 'dpu', 'ath', 'sly', 'zma']\n",
    "    \n",
    "    # Initialize dictionaries to store the highest priority species and hits for each query\n",
    "    query_highest_priority_species = {}\n",
    "    query_highest_priority_hit = {}\n",
    "    \n",
    "    # Iterate through rows in the DataFrame to determine highest priority species and hits for each query\n",
    "    for index, row in final_df.iterrows():\n",
    "        query = row['Query']\n",
    "        species = row['Species.Abbreviation']\n",
    "        \n",
    "        # If this is the first encounter of the query, initialize its highest priority species and hit\n",
    "        if query not in query_highest_priority_species:\n",
    "            query_highest_priority_species[query] = species\n",
    "            query_highest_priority_hit[query] = index\n",
    "        else:\n",
    "            # Check if the current species has higher priority than the stored highest priority species for this query\n",
    "            if species_hierarchy.index(species) < species_hierarchy.index(query_highest_priority_species[query]):\n",
    "                # Update highest priority species and hit for this query\n",
    "                query_highest_priority_species[query] = species\n",
    "                query_highest_priority_hit[query] = index\n",
    "    \n",
    "    # Initialize a list to store rows to be dropped\n",
    "    rows_to_drop = []\n",
    "    \n",
    "    # Iterate through rows in the DataFrame to drop lower priority species hits\n",
    "    for index, row in final_df.iterrows():\n",
    "        query = row['Query']\n",
    "        species = row['Species.Abbreviation']\n",
    "        \n",
    "        # Check if the species for this row is not the highest priority for its query\n",
    "        if index != query_highest_priority_hit[query]:\n",
    "            # Mark the row to be dropped\n",
    "            rows_to_drop.append(index)\n",
    "    \n",
    "    # Drop rows marked for deletion\n",
    "    final_df = final_df.drop(rows_to_drop)\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "# Check if any Queries were lost\n",
    "non_matching_queries(blast_alignment_df, final_df)\n",
    "\n",
    "# Call the function to remove other species hits\n",
    "final_df = remove_other_species_hits(final_df)\n",
    "\n",
    "# Drop the species abbreviation column\n",
    "final_df.drop(columns = ['Species.Abbreviation'], inplace = True)\n",
    "\n",
    "# Check if any Queries were lost\n",
    "non_matching_queries(final_df2, final_df)\n",
    "non_matching_queries(blast_alignment_df, final_df)\n",
    "\n",
    "# Save to csv\n",
    "final_df.to_csv('/home/administrator/Documents/Kaas/Venom_ncRNA_project/Results/blast/miRBase/miRNA_formated_alignment.tsv', sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biopython",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
